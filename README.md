# **preciosCABA: API de An√°lisis y Predicci√≥n de Precios sobre el mercado inmobiliario en la Ciudad de Buenos Aires**

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3+-orange.svg)](https://scikit-learn.org)
[![MySQL](https://img.shields.io/badge/MySQL-8.0+-blue.svg)](https://mysql.com)

## **1\. Prop√≥sito del Proyecto**

Este proyecto es un caso de estudio de ciclo completo (end-to-end) dise√±ado para demostrar habilidades en **An√°lisis e Ingenier√≠a de Datos, Desarrollo de Backend y Machine Learning**. El objetivo es procesar un dataset crudo de propiedades inmobiliarias en la Ciudad de Buenos Aires, almacenarlo en una base de datos limpia y exponerlo a trav√©s de una API RESTful que no solo sirve los datos, sino que tambi√©n ofrece insights anal√≠ticos y **predicciones de precios en tiempo real**.

## **2\. Caracter√≠sticas Principales de la API**

La API, construida con **FastAPI**, ofrece las siguientes funcionalidades:

* **Gesti√≥n de Datos (CRUD):** Endpoints para Crear (POST), Leer (GET), Actualizar (PUT) y Eliminar (DELETE) registros de propiedades.  
* **Consultas Avanzadas:** Endpoint de listado con capacidades de **filtrado** por m√∫ltiples criterios (barrio, ambientes, precio) y **paginaci√≥n**.  
* **Insights Anal√≠ticos:**  
  * GET /estadisticas/precio-por-barrio/: Devuelve estad√≠sticas agregadas (conteo, precio promedio, min/max y **precio promedio por m¬≤**) para cada barrio.  
  * GET /estadisticas/evolucion-mercado/: Analiza la evoluci√≥n de precios y la cantidad de listados a trav√©s de las diferentes fechas de recolecci√≥n de datos.  
* **Predicci√≥n de Precios:** Un endpoint para predecir el precio de una propiedad bas√°ndose en sus caracter√≠sticas usando un modelo de Machine Learning entrenado.

## **3\. Arquitectura y Metodolog√≠a**

El proyecto se desarroll√≥ siguiendo la metodolog√≠a **D.P.E. (Descubrir, Planificar, Ejecutar)**, asegurando un proceso ordenado y de alta calidad.

* **Fase 1: Descubrir (An√°lisis Exploratorio \- EDA):**  
  * Se realiz√≥ una investigaci√≥n exhaustiva del dataset crudo en un Jupyter Notebook (notebooks/1\_analisis\_exploratorio.ipynb).  
  * Se identificaron problemas cr√≠ticos de calidad de datos: tipos de datos incorrectos, valores nulos, inconsistencias en categor√≠as (ej. Location) y la presencia de outliers.  
  * Estos hallazgos fueron la base para planificar el proceso de limpieza.  
* **Fase 2 y 3: Planificar y Ejecutar:**  
  * **ETL:** Un script de Python (scripts/poblar\_db.py) se encarga de la Extracci√≥n, Transformaci√≥n (limpieza, validaci√≥n, imputaci√≥n, estandarizaci√≥n de barrios) y Carga de los datos en una base de datos MySQL.  
  * **Base de Datos:** Se utiliza MySQL para almacenar los datos limpios y estructurados.  
  * **Backend:** La API est√° construida con FastAPI, siguiendo las mejores pr√°cticas de la industria como la gesti√≥n de secretos con archivos .env y la validaci√≥n de datos con Pydantic.

## **4\. Modelo de Machine Learning**

### **4.1 Objetivo del Modelo**
El modelo tiene como objetivo **predecir el precio en USD** de propiedades inmobiliarias en Capital Federal bas√°ndose en caracter√≠sticas estructuradas como ubicaci√≥n, superficie y n√∫mero de ambientes.

### **4.2 Metodolog√≠a: Modelo Base (Baseline)**
Se adopt√≥ una estrategia de **modelo base** como punto de partida, estableciendo un punto de referencia de rendimiento utilizando las caracter√≠sticas m√°s simples y disponibles, antes de abordar complejidades mayores como el Procesamiento de Lenguaje Natural (NLP) sobre las descripciones textuales.

### **4.3 Preparaci√≥n de Datos**
- **Dataset:** 50,248 registros de propiedades con datos limpios y validados
- **Caracter√≠sticas utilizadas:** barrio, ambientes, dormitorios, ba√±os, superficie_total_m¬≤, cocheras
- **Preprocesamiento:** 
  - One-Hot Encoding para la variable categ√≥rica 'barrio' (52 features resultantes)
  - Divisi√≥n 80/20 para entrenamiento y prueba
  - Validaci√≥n de calidad de datos (eliminaci√≥n de registros con precios o barrios nulos)

### **4.4 Modelo Seleccionado**
- **Algoritmo:** RandomForestRegressor (100 estimadores)
- **Justificaci√≥n:** Modelo de conjunto robusto que maneja bien la variabilidad de los datos inmobiliarios
- **Par√°metros:** n_estimators=100, random_state=42, n_jobs=-1

### **4.5 Resultados y Evaluaci√≥n**

#### **M√©tricas de Rendimiento:**
- **R¬≤ (Coeficiente de Determinaci√≥n): 0.8709** 
  - ‚úÖ **Excelente resultado:** El modelo explica aproximadamente el **87% de la variabilidad** en los precios de las propiedades
  - ‚úÖ **Interpretaci√≥n:** Confirma que el modelo ha encontrado patrones s√≥lidos y que las caracter√≠sticas seleccionadas son altamente relevantes

- **RMSE (Error Cuadr√°tico Medio Ra√≠z): $155,871.00 USD**
  - ‚ö†Ô∏è **Contexto importante:** Esta m√©trica refleja la alta varianza inherente en los datos inmobiliarios, donde coexisten propiedades de $50,000 con otras de varios millones
  - ‚úÖ **Precisi√≥n en rango com√∫n:** El modelo es muy preciso en el rango de precios m√°s frecuente, pero tiene dificultades con valores at√≠picos de lujo

#### **An√°lisis de Predicciones:**
- El modelo muestra un comportamiento consistente en el rango de precios m√°s com√∫n ($100K - $500K)
- Las predicciones se alinean bien con los valores reales, como se observa en el an√°lisis de dispersi√≥n
- La capacidad de generalizaci√≥n es s√≥lida, indicando que el modelo puede manejar propiedades nuevas no vistas durante el entrenamiento

### **4.6 Decisiones T√©cnicas Clave**
- **No imputaci√≥n de variable objetivo:** Se descartaron registros sin precio_usd para mantener la integridad del entrenamiento
- **Estrategia de codificaci√≥n:** One-Hot Encoding para barrios mantiene la informaci√≥n categ√≥rica sin introducir orden artificial
- **Validaci√≥n temporal:** Los datos se dividieron aleatoriamente para simular condiciones reales de predicci√≥n

### **4.7 Pr√≥ximas Mejoras Planificadas**
- **Feature Engineering avanzado:** Incorporaci√≥n de NLP en descripciones para extraer caracter√≠sticas como "luminoso", "balc√≥n", "amenities"
- **Modelos avanzados:** Experimentaci√≥n con XGBoost, LightGBM y t√©cnicas de ensemble
- **Validaci√≥n cruzada:** Implementaci√≥n de k-fold CV para evaluaci√≥n m√°s robusta
- **Optimizaci√≥n de hiperpar√°metros:** GridSearch/RandomSearch para mejorar el rendimiento

## **5\. C√≥mo Ejecutar el Proyecto**

1. **Clonar el repositorio.**  
2. **Configurar el Entorno:** Crear un archivo .env en la ra√≠z del proyecto con las credenciales de la base de datos (ver .env.example).  
3. **Instalar Dependencias:**  
   pip install \-r requirements.txt

4. **Poblar la Base de Datos:**  
   * Aseg√∫rese de que la tabla propiedades est√© creada y vac√≠a.  
   * Ejecute el script de ETL: `python scripts/poblar_db.py`  
5. **Entrenar el Modelo de ML:**  
   * Ejecute el notebook de entrenamiento: `jupyter notebook notebooks/entrenamiento_modelo.ipynb`  
   * Esto generar√° los archivos `model.pkl` y `model_columns.pkl` en `src/ml/`
6. **Iniciar la API:**  
   `uvicorn src.api.main:app --reload`

7. **Acceder a la Documentaci√≥n:** Navegue a http://127.0.0.1:8000/docs para interactuar con la API.

## **6\. Endpoints Principales**

### **Gesti√≥n de Propiedades**
- `GET /propiedades/` - Listar propiedades con filtros y paginaci√≥n
- `GET /propiedades/{id}` - Obtener una propiedad espec√≠fica
- `POST /propiedades/` - Crear una nueva propiedad
- `PUT /propiedades/{id}` - Actualizar una propiedad
- `DELETE /propiedades/{id}` - Eliminar una propiedad

### **An√°lisis y Estad√≠sticas**
- `GET /estadisticas/precio-por-barrio/` - Estad√≠sticas agregadas por barrio
- `GET /estadisticas/evolucion-mercado/` - Evoluci√≥n temporal del mercado

### **Machine Learning**
- `POST /predict/` - **Predicci√≥n de precios en tiempo real**
  - **Input:** `{"barrio": "Palermo", "ambientes": 3, "dormitorios": 2, "banos": 2, "superficie_total_m2": 80, "cocheras": 1}`
  - **Output:** `{"predicted_price_usd": 245000.0}`

## **7\. Tecnolog√≠as Utilizadas**

### **Backend y API**
- **FastAPI** - Framework web moderno y r√°pido
- **Pydantic** - Validaci√≥n de datos y serializaci√≥n
- **MySQL** - Base de datos relacional
- **SQLAlchemy** - ORM para Python

### **Machine Learning**
- **Scikit-learn** - Biblioteca de ML
- **Pandas** - Manipulaci√≥n de datos
- **NumPy** - Computaci√≥n num√©rica
- **Pickle** - Serializaci√≥n de modelos

### **An√°lisis y Visualizaci√≥n**
- **Jupyter Notebooks** - An√°lisis exploratorio
- **Matplotlib/Seaborn** - Visualizaciones
- **Pandas** - An√°lisis de datos

## **8\. Estructura del Proyecto**

```
api/
‚îú‚îÄ‚îÄ data/                          # Datos crudos
‚îÇ   ‚îî‚îÄ‚îÄ ventas_deptos.pkl
‚îú‚îÄ‚îÄ notebooks/                     # An√°lisis y entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ EDA.ipynb                 # An√°lisis exploratorio
‚îÇ   ‚îî‚îÄ‚îÄ entrenamiento_modelo.ipynb # Entrenamiento del modelo
‚îú‚îÄ‚îÄ scripts/                       # Scripts de ETL
‚îÇ   ‚îî‚îÄ‚îÄ poblar_db.py
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/                       # API REST
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py               # Aplicaci√≥n principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db_connection.py      # Conexi√≥n a BD
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py            # Modelos Pydantic
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routers/              # Endpoints
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ propiedades.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ predictions.py
‚îÇ   ‚îî‚îÄ‚îÄ ml/                       # Modelo de ML
‚îÇ       ‚îú‚îÄ‚îÄ model.pkl             # Modelo entrenado
‚îÇ       ‚îú‚îÄ‚îÄ model_columns.pkl     # Columnas del modelo
‚îÇ       ‚îú‚îÄ‚îÄ predict.py           # Funci√≥n de predicci√≥n
‚îÇ       ‚îî‚îÄ‚îÄ README.md            # Documentaci√≥n del modelo
‚îú‚îÄ‚îÄ requirements.txt              # Dependencias
‚îî‚îÄ‚îÄ README.md                     # Este archivo
```

## **9\. Estado del Proyecto y Pr√≥ximos Pasos**

### **‚úÖ Completado**
- [x] An√°lisis exploratorio de datos (EDA)
- [x] Pipeline ETL completo con limpieza de datos
- [x] API REST con CRUD completo
- [x] Modelo de ML baseline con RandomForest
- [x] Endpoint de predicci√≥n funcional
- [x] Documentaci√≥n t√©cnica completa

### **üöÄ En Desarrollo**
- [ ] Feature engineering con NLP en descripciones
- [ ] Validaci√≥n cruzada y m√©tricas adicionales
- [ ] Optimizaci√≥n de hiperpar√°metros
- [ ] Testing automatizado

### **üìã Roadmap Futuro**
- [ ] Modelos avanzados (XGBoost, LightGBM)
- [ ] Dashboard interactivo con Streamlit
- [ ] Containerizaci√≥n con Docker
- [ ] CI/CD con GitHub Actions
- [ ] An√°lisis geogr√°fico con mapas
- [ ] Sistema de monitoreo y logging

## **10\. Contribuciones y Contacto**

Este proyecto forma parte de mi portfolio personal como estudiante de programaci√≥n orientado a **Ciencia de Datos e Inteligencia Artificial**.

**Tecnolog√≠as demostradas:**
- üîß **Ingenier√≠a de Datos:** ETL, limpieza, validaci√≥n
- ü§ñ **Machine Learning:** Modelado, evaluaci√≥n, despliegue
- üåê **Desarrollo Backend:** APIs REST, bases de datos
- üìä **An√°lisis de Datos:** EDA, visualizaciones, insights

**Contacto:** joaquin99911@gmail.com

---

*Este proyecto demuestra un ciclo completo de ciencia de datos, desde el an√°lisis exploratorio hasta el despliegue de un modelo de ML en producci√≥n, siguiendo las mejores pr√°cticas de la industria.*