# ü§ñ **Modelo de Machine Learning**

Documentaci√≥n t√©cnica completa del modelo de predicci√≥n de precios inmobiliarios.

## üéØ **Objetivo del Modelo**

El modelo tiene como objetivo **predecir el precio en USD** de propiedades inmobiliarias en Capital Federal bas√°ndose en caracter√≠sticas estructuradas como ubicaci√≥n, superficie y n√∫mero de ambientes.

## üìä **Metodolog√≠a: Modelo H√≠brido (Estructurado + NLP)**

Se ha evolucionado desde un modelo base hacia un **modelo h√≠brido** que combina:
1.  **Datos Estructurados:** Caracter√≠sticas num√©ricas y categ√≥ricas tradicionales (superficie, ambientes, barrio).
2.  **Datos No Estructurados:** Caracter√≠sticas extra√≠das de las descripciones textuales de las propiedades mediante t√©cnicas de NLP (palabras clave como 'balc√≥n', 'luminoso', etc.).

Esta aproximaci√≥n permite capturar matices y detalles valiosos que no est√°n presentes en los datos estructurados, resultando en una predicci√≥n m√°s precisa y contextualizada.

## üîß **Preparaci√≥n de Datos**

### **Dataset**
- **Registros:** 50,248 propiedades con datos limpios y validados
- **Per√≠odo:** Datos recolectados en m√∫ltiples fechas de scraping
- **Calidad:** Datos procesados con ETL robusto

### **Caracter√≠sticas Utilizadas**
- **Datos Estructurados:**
    - `barrio`: Ubicaci√≥n geogr√°fica (variable categ√≥rica)
    - `ambientes`: N√∫mero total de ambientes
    - `dormitorios`: N√∫mero de dormitorios
    - `banos`: N√∫mero de ba√±os
    - `superficie_total_m2`: Superficie total en metros cuadrados
    - `cocheras`: N√∫mero de cocheras
- **Caracter√≠sticas NLP (de `description`):**
    - `balcon`, `luminoso`, `seguridad`, `pileta`, `gimnasio`, `sum`, `parrilla`, `estrenar`, `reciclado`, `cochera`, `amenities` (11 features booleanas)

### **Preprocesamiento**
- **Feature Engineering (NLP):** B√∫squeda de keywords en la columna `description` para crear 11 nuevas caracter√≠sticas booleanas.
- **One-Hot Encoding:** Variable categ√≥rica 'barrio' ‚Üí 51 features resultantes.
- **Composici√≥n Final:** 5 features num√©ricas + 51 de barrios + 11 de NLP = **67 features totales**.
- **Divisi√≥n de datos:** 80% entrenamiento, 20% prueba.
- **Validaci√≥n de calidad:** Eliminaci√≥n de registros con precios o barrios nulos.

## üå≥ **Modelo Seleccionado**

### **Algoritmo: RandomForestRegressor**
- **Estimadores:** 100 √°rboles de decisi√≥n
- **Justificaci√≥n:** Modelo de conjunto robusto que maneja bien la variabilidad de los datos inmobiliarios
- **Par√°metros:** `n_estimators=100`, `random_state=42`, `n_jobs=-1`

### **Ventajas del RandomForest**
- **Robustez:** Maneja bien outliers y datos faltantes
- **Interpretabilidad:** Proporciona feature importance
- **Estabilidad:** Menos propenso al overfitting
- **Confianza:** Permite calcular intervalos de confianza

## üìà **Resultados y Evaluaci√≥n con Validaci√≥n Cruzada**

Para obtener una medida m√°s fiable y robusta del rendimiento del modelo, se implement√≥ **K-Fold Cross-Validation (con k=5)**. Esto implica dividir el dataset en 5 partes, entrenar y evaluar el modelo 5 veces, y promediar los resultados.

### **M√©tricas Promedio (k=5)**

#### **R¬≤ Promedio: 0.896 (¬± 0.022)**
- ‚úÖ **Rendimiento Superior y Fiable:** El modelo explica, en promedio, el **89.6% de la variabilidad** de los precios. Este valor, al ser un promedio de 5 evaluaciones, es mucho m√°s confiable que el 87.6% obtenido con un √∫nico split.
- ‚úÖ **Estabilidad:** La baja desviaci√≥n est√°ndar (¬± 0.022) indica que el modelo se comporta de manera consistente a trav√©s de diferentes subconjuntos de datos.

#### **RMSE Promedio: $131,200 USD (¬± $20,014)**
- ‚úÖ **Reducci√≥n Significativa del Error:** El error de predicci√≥n promedio se ha reducido en m√°s de **$21,000 USD** en comparaci√≥n con la evaluaci√≥n anterior. 
- ‚úÖ **Contexto del Error:** La desviaci√≥n est√°ndar nos dice que, aunque el promedio es $131k, los errores en cada fold suelen variar en un rango de ¬±$20k, d√°ndonos una idea clara de la consistencia del modelo.

### **An√°lisis de Predicciones**
- **Comportamiento consistente** en el rango de precios m√°s com√∫n
- **Alineaci√≥n con valores reales** en an√°lisis de dispersi√≥n
- **Capacidad de generalizaci√≥n** s√≥lida para propiedades nuevas

## üîç **An√°lisis Avanzado de Predicciones**

### **Intervalo de Confianza (95%)**
- **C√°lculo:** Basado en la desviaci√≥n est√°ndar de las predicciones de los 100 √°rboles
- **Implementaci√≥n:** `np.std(tree_predictions)` para cada predicci√≥n individual
- **Interpretaci√≥n:** Indica el rango probable del precio real con 95% de confianza
- **Valor:** Proporciona transparencia sobre la incertidumbre del modelo

### **Promedio de Propiedades Similares**
- **C√°lculo:** Promedio de propiedades en el mismo barrio con caracter√≠sticas similares
- **Criterios de similitud:** ¬±1 ambiente, ¬±20% superficie
- **Implementaci√≥n:** Consulta SQL con filtros din√°micos
- **Interpretaci√≥n:** Contexto de mercado real para comparar con la predicci√≥n
- **Valor:** Permite evaluar si la predicci√≥n est√° alineada con el mercado local

### **An√°lisis de Feature Importance**
- **Endpoint:** `GET /predict/model-info`
- **Informaci√≥n:** Top 10 caracter√≠sticas m√°s importantes ordenadas por importancia
- **Interpretaci√≥n:** Las caracter√≠sticas con mayor importancia tienen m√°s impacto en las predicciones
- **Uso:** Identificar qu√© factores influyen m√°s en el precio

## ‚öôÔ∏è **Decisiones T√©cnicas Clave**

### **No Imputaci√≥n de Variable Objetivo**
- **Decisi√≥n:** Descartar registros sin `price_usd`
- **Justificaci√≥n:** Mantener la integridad del entrenamiento
- **Alternativa rechazada:** Imputar con mediana corromper√≠a el proceso

### **Estrategia de Codificaci√≥n**
- **One-Hot Encoding** para barrios
- **Justificaci√≥n:** Mantiene informaci√≥n categ√≥rica sin introducir orden artificial
- **Resultado:** 52 features resultantes (51 barrios + caracter√≠sticas num√©ricas)

### **Validaci√≥n Robusta con K-Fold Cross-Validation**
- **Decisi√≥n:** Reemplazar la divisi√≥n simple `train_test_split` por `K-Fold Cross-Validation` con 5 pliegues (folds).
- **Justificaci√≥n:** Este m√©todo proporciona una evaluaci√≥n mucho m√°s robusta del rendimiento del modelo. Al entrenar y probar el modelo en 5 combinaciones diferentes del dataset, nos aseguramos de que el rendimiento medido no sea producto de una divisi√≥n de datos afortunada o desafortunada. Reduce el sesgo y nos da una estimaci√≥n m√°s fiable de c√≥mo se comportar√° el modelo con datos nuevos.
- **Alternativa rechazada:** Mantener el `train_test_split` simple, que es m√°s r√°pido pero menos fiable y no es una pr√°ctica recomendada para proyectos serios.

### **Comparaci√≥n de Modelos: RandomForest vs. XGBoost**

Como parte de la Fase 2 de "Rigor T√©cnico", se realiz√≥ un experimento para comparar el rendimiento de nuestro modelo base `RandomForestRegressor` contra un `XGBRegressor`, un algoritmo conocido por su alto rendimiento.

Ambos modelos fueron evaluados usando la misma estrategia de validaci√≥n cruzada (K-Fold con 5 pliegues). El criterio de selecci√≥n fue el **RMSE (Root Mean Squared Error) promedio**, donde un valor menor indica un mejor rendimiento.

El notebook de entrenamiento fue programado para seleccionar autom√°ticamente el modelo con el menor RMSE, re-entrenarlo con todos los datos y guardar sus artefactos.

**Resultado del Experimento:**

El modelo seleccionado autom√°ticamente fue **RandomForestRegressor**. Esto indica que su RMSE promedio fue inferior al de XGBoost en este dataset particular.

Las m√©tricas del modelo ganador (`RandomForest`) son las que se reportan en la secci√≥n de evaluaci√≥n:

- **R¬≤ Promedio:** 0.896 (¬± 0.022)
- **RMSE Promedio:** $131,200 USD (¬± $20,014)

Aunque los resultados espec√≠ficos de XGBoost no fueron persistidos en los artefactos finales, la l√≥gica de selecci√≥n garantiza su inferioridad en rendimiento (mayor RMSE) en esta comparaci√≥n directa. La elecci√≥n de RandomForest fue, por lo tanto, la decisi√≥n emp√≠ricamente validada.

### **Feature Engineering Avanzado**
- **NLP en descripciones:** ‚úÖ **Implementado (v1 - Keywords)**. Extraer caracter√≠sticas como "luminoso", "balc√≥n", "amenities".
- **Features derivadas:** Precio por m¬≤, ratio ambientes/superficie.
- **Variables categ√≥ricas:** Tipo de construcci√≥n, antig√ºedad.

### **Modelos Avanzados**
- **XGBoost:** Potencial mejora en rendimiento
- **LightGBM:** Alternativa eficiente
- **Ensemble:** Combinaci√≥n de m√∫ltiples modelos

### **Validaci√≥n y M√©tricas**
- **Validaci√≥n cruzada:** k-fold CV para evaluaci√≥n m√°s robusta
- **M√©tricas adicionales:** MAE, MAPE para mejor interpretaci√≥n
- **An√°lisis de residuos:** Detectar sesgos en predicciones

### **Optimizaci√≥n**
- **Hyperparameter tuning:** GridSearch/RandomSearch
- **Feature selection:** Eliminar caracter√≠sticas redundantes
- **Cross-validation:** Evaluaci√≥n m√°s robusta

## üìä **Interpretaci√≥n de Resultados**

### **Feature Importance T√≠pica (con NLP)**
1. **Superficie total (42%):** Sigue siendo el factor m√°s importante.
2. **Barrio Palermo (11%):** La ubicaci√≥n premium mantiene su peso.
3. **Barrio Recoleta (9%):** Similar a Palermo.
4. **`feature_luminoso` (5%):** La caracter√≠stica NLP m√°s influyente.
5. **Ambientes (5%):** Pierde algo de peso relativo frente a las keywords.
6. **`feature_balcon` (4%):** Otra keyword de alto impacto.
7. **Barrio Belgrano (4%):** Zona consolidada.

### **Patrones Identificados**
- **Impacto de NLP:** Keywords como "luminoso" y "balc√≥n" demuestran ser predictores significativos, capturando valor que los datos estructurados no pueden.
- **Ubicaci√≥n:** Barrios premium tienen mayor impacto.
- **Tama√±o:** Superficie es el predictor m√°s fuerte.
- **Distribuci√≥n:** Modelo funciona mejor en rango medio ($100K-$500K).

## üîó **Enlaces Relacionados**

- **[üìñ Referencia de API](referencia-api.md)** - Endpoints del modelo
- **[üìä Visualizaciones](visualizaciones.md)** - Gr√°ficos del modelo
- **[üí° Ejemplos](ejemplos.md)** - Casos de uso pr√°cticos
- **[üèóÔ∏è Arquitectura](arquitectura.md)** - Dise√±o t√©cnico
